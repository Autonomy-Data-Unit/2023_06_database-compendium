# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/05_Embeddings_analysis.ipynb.

# %% auto 0
__all__ = ['cos_similarity', 'svm_similarity']

# %% ../../nbs/05_Embeddings_analysis.ipynb 5
import pandas as pd
import plotly.express as px
import matplotlib.pyplot as plt
import numpy as np
import math
from sklearn.decomposition import PCA
import openai

# %% ../../nbs/05_Embeddings_analysis.ipynb 11
def cos_similarity(data, # Dataset as a dataframe that we want to use to compare rows
                   compare_row=0, # The row in the dataset that will be compared with all the others
                   num=10): # The number of similar datasets that will be returned (in descending order)

    """Using cosine similarity to find the most closely related datasets"""

    if type(data.iloc[0, 0]) == str:
        labels = data.iloc[:, 0]
        vectors = data.iloc[:, 1:]
    else:
        labels = data.index.values
        vectors = data.iloc[:, :]
        
    query = vectors.iloc[compare_row, :].values
    vectors = vectors.drop(compare_row).values
    
    """ 
    Calculate the cosine similarity between the query vector and each embedding vector
    and sort in descending order.
    
    https://github.com/karpathy/randomfun/blob/master/knn_vs_svm.ipynb
    """
    similarities = vectors.dot(query) # This gives inconsistent results!!
    sorted_ix = np.argsort(-similarities)
                           
    updated_labels = np.delete(labels, compare_row)

    return [updated_labels[i] for i in sorted_ix[:num]], similarities[sorted_ix[:num]]

# %% ../../nbs/05_Embeddings_analysis.ipynb 14
from sklearn import svm

def svm_similarity(data, # Dataset as a dataframe that we want to use to compare rows
                   compare_row=0, # The row in the dataset that will be compared with all the others
                   num=10): # The number of similar datasets that will be returned (in descending order)

    """Using SVM to find the most closley related datasets"""
    
    if type(data.iloc[0, 0]) == str:
        labels = data.iloc[:, 0]
        vectors = data.iloc[:, 1:]
    else:
        labels = data.index.values
        vectors = data.iloc[:, :]

    #vectors = vectors.drop(compare_row).values
    target = np.zeros(len(vectors))
    target[compare_row] = 1

    clf = svm.LinearSVC(class_weight='balanced', verbose=False, 
                        max_iter=40000, tol=1e-6, C=1, dual=True)
    clf.fit(vectors, target)
                       
    similarities = clf.decision_function(vectors)
    sorted_ix = np.argsort(-similarities)
    sorted_ix = sorted_ix[sorted_ix != compare_row] # we don't want the compare dataset compared with itself                
    
    return [labels[i] for i in sorted_ix[:num]], similarities[sorted_ix[:num]]

# %% ../../nbs/05_Embeddings_analysis.ipynb 17
from sklearn.cluster import KMeans
from sklearn.cluster import AgglomerativeClustering
import scipy.cluster.hierarchy as shc

# %% ../../nbs/05_Embeddings_analysis.ipynb 40
from pyvis.network import Network
from IPython.display import display
