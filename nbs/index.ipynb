{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from database_compendium.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from database_compendium.utils import (\n",
    "    ONS_scraper_functions as osf,\n",
    "    Nomis_scraper_functions as nsf,\n",
    "    insolvency_stats_scrapers as iss,\n",
    "    NHS_QualityOutcomes_scrapers as qos,\n",
    "    police_data_scrapers as pds,\n",
    "    column_matching as cm\n",
    ")\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Compendium\n",
    "\n",
    "> Collecting, storing, and exploring metadata of datasets from the ONS API, Nomis API, gov.uk, police data API, and nhs.uk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install database_compendium\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python 3.x\n",
    "- requests library\n",
    "- pandas library\n",
    "- BeautifulSoup library\n",
    "- re (Regular Expression) module\n",
    "- Math\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following shows how the functions can be used to collect metadata on the datasets available from each source.  \n",
    "- These scripts are aimed at retrieving dataset titles, two descriptions (long and short), column titles, unique non-numeric column values, and the release date / date of last update.  \n",
    "- Titles and descriptions are given as strings, columns as a list, and unique column values as a dictionary (with the key being the column title).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONS Functions\n",
    "> ONS functions include: get_ONS_datasets_titles_descriptions(), get_ONS_long_description(), get_ONS_datasets_urls(), find_ONS_cols(), find_ONS_cols_and_unique_vals()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  Quarterly personal well-being estimates\n",
      "\n",
      "Description:  Seasonally and non seasonally-adjusted quarterly estimates of life satisfaction, feeling that the things done in life are worthwhile, happiness and anxiety in the UK.\n",
      "\n",
      "Long_description:  We are currently reviewing the measures of national well-being and will update this page in summer 2\n",
      "\n",
      "Columns:  ['v4_2', 'LCL', 'UCL', 'yyyy-qq', 'Time', 'uk-only', 'Geography', 'measure-of-wellbeing', 'MeasureOfWellbeing', 'wellbeing-estimate', 'Estimate', 'seasonal-adjustment', 'SeasonalAdjustment']\n",
      "\n",
      "Unique_parameters:  {'v4_2': None, 'LCL': None, 'UCL': None, 'yyyy-qq': ['2017-q2', '2011-q2', '2020-q2', '2016-q4', '2021-q3', '2020-q3', '2014-q3', '2019-q4', '2022-q2', '2021-q1', '2015-q1', '2013-q4', '2022-q4', '2018-q2', '2017-q3', '2020-q1', '2017-q1', '2012-q4', '2021-q4', '2015-q4', '2019-q2', '2022-q1', '2018-q4', '2015-q3', '2014-q2', '2013-q1', '2016-q1', '2022-q3', '2018-q3', '2015-q2', '2019-q1', '2020-q4', '2014-q1', '2014-q4', '2021-q2', '2018-q1', '2013-q3', '2019-q3', '2012-q1', '2011-q3', '2016-q3', '2016-q2', '2012-q3', '2012-q2', '2017-q4', '2013-q2', '2011-q4'], 'Time': ['2017 Q2', '2011 Q2', '2020 Q2', '2016 Q4', '2021 Q3', '2020 Q3', '2014 Q3', '2019 Q4', '2022 Q2', '2021 Q1', '2015 Q1', '2013 Q4', '2022 Q4', '2018 Q2', '2017 Q3', '2020 Q1', '2017 Q1', '2012 Q4', '2021 Q4', '2015 Q4', '2019 Q2', '2022 Q1', '2018 Q4', '2015 Q3', '2014 Q2', '2013 Q1', '2016 Q1', '2022 Q3', '2018 Q3', '2015 Q2', '2019 Q1', '2020 Q4', '2014 Q1', '2014 Q4', '2021 Q2', '2018 Q1', '2013 Q3', '2019 Q3', '2012 Q1', '2011 Q3', '2016 Q3', '2016 Q2', '2012 Q3', '2012 Q2', '2017 Q4', '2013 Q2', '2011 Q4'], 'uk-only': ['K02000001'], 'Geography': ['United Kingdom'], 'measure-of-wellbeing': ['anxiety', 'worthwhile', 'happiness', 'life-satisfaction'], 'MeasureOfWellbeing': ['Anxiety', 'Worthwhile', 'Happiness', 'Life satisfaction'], 'wellbeing-estimate': ['poor', 'very-good', 'good', 'average-mean', 'fair'], 'Estimate': ['Poor', 'Very good', 'Good', 'Average (mean)', 'Fair'], 'seasonal-adjustment': ['non-seasonal-adjustment', 'seasonal-adjustment'], 'SeasonalAdjustment': ['Non-seasonally adjusted', 'Seasonally adjusted']}\n",
      "\n",
      "Latest_release:  2023-05-12T00:00:00.000Z\n"
     ]
    }
   ],
   "source": [
    "from database_compendium.utils.ONS_scraper_functions import *\n",
    "\n",
    "# Titles and Descriptions\n",
    "titles, descriptions = get_ONS_datasets_titles_descriptions()\n",
    "\n",
    "# Long Descriptions\n",
    "long_description = get_ONS_long_description()\n",
    "\n",
    "# Dataset URLs which are used to open the dataset and read the column data\n",
    "urls = get_ONS_datasets_urls()\n",
    "\n",
    "# Dataset Columns\n",
    "columns = find_ONS_cols(urls[0])\n",
    "\n",
    "# Dataset Unique Column Values\n",
    "unique_column_vals = find_ONS_cols_and_unique_vals(urls[0])\n",
    "\n",
    "# In this case there isn't a function that gets the date but it can easily be done \n",
    "# using the urls as follows\n",
    "response = requests.get(urls[0], timeout=1)\n",
    "latest_release = str(response.json()['release_date'])\n",
    "\n",
    "# Display the output of each function\n",
    "print('Title: ', titles[0])\n",
    "print('\\nDescription: ', descriptions[0]) \n",
    "print('\\nLong_description: ', long_description[0][:100])\n",
    "print('\\nColumns: ', columns)\n",
    "print('\\nUnique_parameters: ', unique_column_vals)\n",
    "print('\\nLatest_release: ', latest_release)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomis Functions\n",
    "> Nomis functions include: get_nomis_datasets_titles_descriptions(), get_nomis_dataset_parameters(), and get_nomis_last_updated()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database_compendium.utils.Nomis_scraper_functions import *\n",
    "\n",
    "# Titles, Descriptions, and long Descriptions\n",
    "titles, descriptions, l_descriptions = get_nomis_datasets_titles_descriptions()\n",
    "\n",
    "# Unfortunately the Nomis api doesn't currently have a way of collecting columns from a dataset without specifying parameters \n",
    "# before hand. I use a blank array so the data fits in a combined dataframe with the data from other sources.\n",
    "cols = np.empty(len(titles))\n",
    "\n",
    "# Dataset Unique parameters\n",
    "params = get_nomis_datasets_parameters()\n",
    "\n",
    "# Most recent release date\n",
    "latest_release = get_nomis_last_updated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insolvency Functions\n",
    "> The insolvency statistics are released as an excel file once a month, this means most of there are fewer functions as almost all the data needed is in said file. Functions include: get_insolvency_stats(), get_mis_description(), and get_mis_last_updated()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database_compendium.utils.insolvency_stats_scrapers import *\n",
    "\n",
    "# Insolvency stats are given as a dictionary of dataframes where the key is the dataset title\n",
    "insolvency_stats, long_desc = get_insolvency_stats()\n",
    "titles = list(insolvency_stats.keys())\n",
    "\n",
    "# The descriptions and latest releases are all the same\n",
    "description = get_mis_description()\n",
    "latest_release = get_mis_last_updated()\n",
    "\n",
    "# Dataset columns and unique column values\n",
    "cols = list(insolvency_stats[titles[0]].columns)\n",
    "col_data = get_insolvency_unique_column_vals(insolvency_stats[titles[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Police Data Functions\n",
    "> The police data is a bit more awkward as it requires either a latitude and longitude or a poly-area which is made up of latitude and longitude pairs. In an attempt to make things easier the get_constituency_coordinates() function was added which returns a dictionary containing every westminster parliamentary constituency and four coordinates as a very low res poly-area. For those with no location, the search is done by police force.\n",
    "> Functions include: get_constituency_coordinates(), get_street_level_crimes(), get_crimes_no_loc(), get_searches_no_loc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database_compendium.utils.police_data_scrapers import *\n",
    "\n",
    "# Coordinates for all constituencies (UK) - for a list of contituency names use constituency_coords.keys()\n",
    "constituency_coords = get_constituency_coordinates()\n",
    "\n",
    "street_level_crimes, sl_last_updated = get_street_level_crimes(constituency_coords['Bethnal Green and Bow'], '2023-03', 'poly')\n",
    "stop_searches, ss_last_updated = get_stop_searches(constituency_coords['Bethnal Green and Bow'], '2023-03', 'poly')\n",
    "\n",
    "no_loc_crimes = get_crimes_no_loc('metropolitan', '2023-03')\n",
    "searches_no_loc = get_searches_no_loc('metropolitan', '2023-03')\n",
    "\n",
    "# Given a dataset gets unique column values - done individually \n",
    "col_data = get_unique_col_vals(street_level_crimes)\n",
    "\n",
    "# Columns are the keys from the unique column values \n",
    "cols = col_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NHS Quality and Outcomes\n",
    "> As with the insolvency stats, this comes as an excel file.\n",
    "> Functions include: get_NHS_qualityOutcomes(), get_qualityOutcomes_uniqueColumnValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database_compendium.utils.NHS_QualityOutcomes_scrapers import *\n",
    "\n",
    "# Returns dictionary of dataframes.\n",
    "# The latest release and long description are both the same for all datasets in this file\n",
    "NHS_quality_outcomes, long_description, latest_release = get_NHS_qualityOutcomes()\n",
    "\n",
    "# Datasets Titles\n",
    "titles = list(NHS_quality_outcomes.keys())\n",
    "\n",
    "sheet = NHS_quality_outcomes[titles[0]]\n",
    "cols, uniqueParams = get_qualityOutcomes_uniqueColumnValues(sheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scripts interact with the ONS, Nomis, and Police APIs and various web pages. Be mindful of their usage to avoid overloading the servers or violating any terms of use of the APIs.\n",
    "\n",
    "Remember that web scraping can be subject to changes in the website's structure and terms of use. Keep the scripts up-to-date and adapt them as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the provided documentation is a general guide based on the information available in the code snippet. You might need to adjust the documentation according to the specific needs of your project and any further developments made to the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on the functions and the how the code works check the functions files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
