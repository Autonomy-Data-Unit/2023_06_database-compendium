{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e380822-8a40-4948-82af-a62cb43ab3ea",
   "metadata": {},
   "source": [
    "# Scrape Data from the Nomis API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f6155e-1af8-4255-9d9e-f7ecfad99a86",
   "metadata": {},
   "source": [
    "- Automatically get a list of datasets available via the API and their descriptions\n",
    "- Get the date each dataset was last updated\n",
    "- Get the unique parameters for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbfaf2b-fe3a-4a16-9dbf-b3ad47473b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils.Nomis_scraper_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf065561-1138-4a4b-8321-42e7aa229952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654585b9-7d3a-4e3b-8ec4-0882147e986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3222b90-a0a3-4677-a4dc-0b097e3180a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_nomis_datasets_titles_descriptions():\n",
    "\n",
    "    \"\"\"\n",
    "    Function to get the names and descriptions of all the datasets available via \n",
    "    the Nomis api.\n",
    "\n",
    "    Note:\n",
    "    Unfortunately the Nomis api requires we specify the parameters (such as \n",
    "    geography, age, sex, etc) in order to form a uri and download a dataset.\n",
    "    These parameters change depending on the data we are dealing with making\n",
    "    automation very difficult.\n",
    "    \"\"\"\n",
    "\n",
    "    url = \"https://www.nomisweb.co.uk/api/v01/dataset/def.sdmx.json\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    temp = data['structure']['keyfamilies']['keyfamily']\n",
    "    nomis_datasets_names = []\n",
    "    nomis_datasets_descriptions = []\n",
    "    nomis_long_descriptions = []\n",
    "    for dataset in temp:\n",
    "        nomis_datasets_names.append(dataset['name']['value'])\n",
    "\n",
    "        if 'description' in dataset:\n",
    "            nomis_datasets_descriptions.append(dataset['description']['value'])\n",
    "        else:\n",
    "            nomis_datasets_descriptions.append(float('nan'))\n",
    "\n",
    "    url = \"https://www.nomisweb.co.uk/api/v01/dataset/def.sdmx.json\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    temp = data['structure']['keyfamilies']['keyfamily']\n",
    "    nomis_datasets_names = []\n",
    "    nomis_datasets_descriptions = []\n",
    "    \n",
    "    for dataset in temp:\n",
    "        nomis_datasets_names.append(dataset['name']['value'])\n",
    "\n",
    "        if 'description' in dataset:\n",
    "            nomis_datasets_descriptions.append(dataset['description']['value'])\n",
    "        else:\n",
    "            nomis_datasets_descriptions.append('')\n",
    "\n",
    "        # Long description in this case may not necessarily be useful\n",
    "        temp_dscptn = ''\n",
    "        for annotation in dataset['annotations']['annotation']:\n",
    "            temp_dscptn += str(annotation['annotationtext']) + '\\n'\n",
    "        nomis_long_descriptions.append(temp_dscptn)\n",
    "\n",
    "    return nomis_datasets_names, nomis_datasets_descriptions, nomis_long_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65603c8-9866-406f-8033-1940a5e76407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: TS058 - Distance travelled to work\n",
      "Description: \n",
      "Long Description: Current (being actively updated)\n",
      "Persons\n",
      "census_2021_ts\n",
      "oa,msoa,la\n",
      "All usual residents aged 16 years and over in employment the week before the census\n",
      "c2021ts058\n",
      "2022-12-08 09:30:00\n",
      "2022-12-08 09:30:00\n",
      "About this dataset\n",
      "This dataset provides Census 2021 estimates that classify usual residents aged 16 years and over in employment the week before the census in England and Wales by the distance they travelled to work. The estimates are as at Census Day, 21 March 2021.\n",
      "    Census 2021 took place during a period of rapid change. We gave extra guidance to help people on furlough answer the census questions about work. However, we are unable to determine how furloughed people followed the guidance. Take care when using this data for planning purposes. Read more about specific quality considerations in our https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/employmentandemployeetypes/methodologies/traveltoworkqualityinformationforcensus2021[Labour market quality information for Census 2021 methodology].\n",
      "   \n",
      "   National Park data are created by plotting unique properties as identified by their Unique Property Reference Number or postcodes into National Park boundaries current at December 2022. This differs from the OA best fit methodology used for other geographic level data.\n",
      "Protecting personal data\n",
      "Sometimes we need to make changes to data if it is possible to identify individuals. This is known as statistical disclosure control. In Census 2021, we:\n",
      "\n",
      "* Swapped records (targeted record swapping), for example, if a household was likely to be identified in datasets because it has unusual characteristics, we swapped the record with a similar one from a nearby small area. Very unusual households could be swapped with one in a nearby local authority.\n",
      "* Added small changes to some counts (cell key perturbation), for example, we might change a count of four to a three or a five. This might make small differences between tables depending on how the data are broken down when we applied perturbation.\n",
      "2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titles, descriptions, long_descriptions = get_nomis_datasets_titles_descriptions()\n",
    "print('Title: ' + titles[1340] + '\\n' + 'Description: ' + descriptions[1340] + '\\n' + 'Long Description: ' + long_descriptions[1340])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7074a769-4b95-4ee0-bf40-d708876e2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_nomis_last_updated():\n",
    "    \"\"\" \n",
    "    Get the date the each dataset was last updated on.\n",
    "    If no date exists then set value to None.\n",
    "    \"\"\"\n",
    "    last_updated = []\n",
    "    i = 0\n",
    "    url = \"https://www.nomisweb.co.uk/api/v01/dataset/def.sdmx.json\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    try:\n",
    "        keyfamilies = response.json()['structure']['keyfamilies']['keyfamily']\n",
    "        \n",
    "        for keyfamily in keyfamilies:\n",
    "            last_updated.append(None) # Ensure there is something in place for each dataset even if there is no last updated value\n",
    "            annotations = keyfamily['annotations']['annotation']\n",
    "        \n",
    "            for annotation in annotations:\n",
    "                if annotation['annotationtitle'] == 'LastUpdated':\n",
    "                    last_updated[i] = annotation['annotationtext']\n",
    "            i += 1\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "    return last_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bb37a3-4057-45e3-a07f-9b5fe33affb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-07-11 07:00:00'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first date in the list\n",
    "get_nomis_last_updated()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b09e67f-83d8-4f9f-aa9b-42d5e2954154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_nomis_datasets_parameters():\n",
    "\n",
    "    \"\"\"\n",
    "    Function to collect the IDs and parameters for each dataset on the Nomis API.\n",
    "\n",
    "    How does it work?\n",
    "    Every dataset has parameter categories e.g. geography, sex, age. Each of these categories\n",
    "    then has various parameters e.g. age - 0-12, 13-25, etc. To get the parameters we must first\n",
    "    loop through every dataset and collect the parameter categories and the IDs. Using the IDs\n",
    "    (unique to each dataset) to specify the dataset and the categories we can then get the \n",
    "    available parameters specific to each dataset. These are saved to a dictionary with the keys\n",
    "    being the parameter categories and the values being the parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    MAX_RETRIES = 5\n",
    "    \n",
    "    url = \"https://www.nomisweb.co.uk/api/v01/dataset/def.sdmx.json\"\n",
    "\n",
    "    for i in range(MAX_RETRIES):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "        except:\n",
    "            time.sleep(2*i)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    \n",
    "    data = response.json()\n",
    "\n",
    "    parameter_names_list = []   # Stores the lists of parameter names for all available datasets\n",
    "    ids = []                    # Stores the unique id for each dataset\n",
    "    datasets = data['structure']['keyfamilies']['keyfamily']    # Focuses on the metadata\n",
    "\n",
    "\n",
    "    \"\"\" Loops through available datasets and collects the ID's and available parameter categories e.g. Geography \"\"\"\n",
    "    for dataset in datasets:\n",
    "        dimensions = dataset['components']['dimension']\n",
    "\n",
    "        parameter_names = {}  # dictionary which stores the parameter categories as the keys and a list of the options for each category for a single dataset\n",
    "        ids.append(dataset['id'])\n",
    "        for dimension in dimensions:\n",
    "            #parameter_names.append(dimension['conceptref'])\n",
    "            parameter_names[dimension['conceptref']] = None\n",
    "\n",
    "        parameter_names_list.append(parameter_names)    # stores parameter categories and options for every dataset (list of dictionaries)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Loops through the ID's which allows us to specify the dataset we want to extract metadata from.\n",
    "    Then also loops through each parameter category available for each dataset and creates a list\n",
    "    of all the options for each category. \n",
    "    e.g. Geography: ['United Kingdom', 'Great Britain', 'England', 'Wales', 'Scotland', 'Northern Ireland', 'England and Wales'].\n",
    "    This will then provide a list containing every possible parameter for every dataset\n",
    "\n",
    "    Took me about 30 mins to run. To avoid running again I saved the list as parameter_names_list.txt\n",
    "    \"\"\"\n",
    "    for i in range(len(ids)):\n",
    "\n",
    "        for parameter_name in list(parameter_names_list[i].keys()):\n",
    "\n",
    "            url = 'https://www.nomisweb.co.uk/api/v01/dataset/' + ids[i] + '/' + parameter_name + '.def.sdmx.json'\n",
    "            response = requests.get(url)\n",
    "            info = response.json()\n",
    "\n",
    "            values = info['structure']['codelists']['codelist'][0]['code']\n",
    "            temp_list = []\n",
    "            for value in values:\n",
    "                try:\n",
    "                    temp_list.append(value['description']['value'])\n",
    "                except KeyError:\n",
    "                    continue    # move on if there is no existing value\n",
    "\n",
    "            parameter_names_list[i][parameter_name] = temp_list\n",
    "\n",
    "    return parameter_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c38e895-d84f-495e-91fd-1b0aef915e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_nomis_datasets_parameters()\n",
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db79bf83-2a59-4479-966d-41e707513b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
